{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Import modules</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import operator\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Reading files from directory</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all data from .txt files from directory (data placed in created List, in these case directory was placed on current user Desktop\n",
    "\n",
    "text_from_all_files = []\n",
    "\n",
    "all_files = glob.glob(r'C:\\Users\\altz7\\Desktop\\test_folder\\*.txt')\n",
    "for file in all_files:\n",
    "    open_file = open(file, encoding=\"utf-8\")\n",
    "    combined_data = open_file.read()\n",
    "    text_from_all_files.append(combined_data)\n",
    "    open_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Preprocessing data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a string object from list\n",
    "final_text = ''.join(text_from_all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace unwanted characters that will not be catched by Stopwords standard vocabulary \n",
    "final_text = final_text.replace('...', '.').replace('--', '').replace('***', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove cases where two or more whitespaces where used insted of one\n",
    "final_text = ' '.join(final_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(final_text) #tokenize words from input text files\n",
    "words = [word for word in words if len(word) > 1] # Remove single-character tokens (mostly punctuation)\n",
    "words = [word for word in words if not word.isnumeric()] # Remove numbers\n",
    "words = [word.lower() for word in words] # Lowercase all words\n",
    "words = [word for word in words if word not in stopwords.words('english')] # Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Creating list of N-grams</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_list = []\n",
    "def ngrams_from_text():\n",
    "    str1 = ' '.join([str(elem) for elem in words]) #convert list object back into string, N-gram requirements\n",
    "    n = 5 #In these line you can control the size of each N-gram. Number equals to number of words in each N-gram\n",
    "    bigrams = ngrams(str1.split(), n)\n",
    "    for gram in bigrams:\n",
    "        ngrams_list.append(gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Creating word frequency list with metric values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency():\n",
    "    cv = CountVectorizer()\n",
    "    cv_fit=cv.fit_transform(words)\n",
    "    word_list = cv.get_feature_names()\n",
    "    count_list = cv_fit.toarray().sum(axis=0)\n",
    "    dictionary_test = dict(zip(word_list, count_list))\n",
    "    return dictionary_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Multiprocessing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    p1 = Process(target = word_frequency())\n",
    "    p2 = Process(target = ngrams_from_text())\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Saving data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving N-grams list in .txt file. Directory and file names could be changed to any other values\n",
    "\n",
    "with open(r'C:\\Users\\altz7\\Desktop\\test_folder\\Ngrams_list.txt', 'w') as file_output:\n",
    "    for list_item in ngrams_list:\n",
    "        file_output.write(str(f\"{list_item}\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving N-grams list in .csv file. Directory and file names could be changed to any other values\n",
    "\n",
    "df1 = pd.DataFrame(data={\"N-grams\": ngrams_list})\n",
    "df1.to_csv(r'C:\\Users\\altz7\\Desktop\\test_folder\\Ngrams_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving frequency_list as CSV format, more freindly way, cause we can specify columns easily \n",
    "\n",
    "#in this line you can control how much values you like to list from the top. In these case it will be listed first 25 frequent words.\n",
    "dictionary_test = word_frequency()\n",
    "word_frequency_dict = dict(sorted(dictionary_test.items(), key=operator.itemgetter(1), reverse=True)[:26])\n",
    "\n",
    "df = pd.DataFrame(word_frequency_dict.items(), columns=[\"word\", \"frequency\"])\n",
    "\n",
    "df.to_csv(r'C:\\Users\\altz7\\Desktop\\test_folder\\Words_frequency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just in case you need frequency data in txt - these lines convert CSV file to TXT file format\n",
    "with open(r'C:\\Users\\altz7\\Desktop\\test_folder\\Words_frequency.txt', \"w\") as my_output_file:\n",
    "    with open(r'C:\\Users\\altz7\\Desktop\\test_folder\\Words_frequency.csv') as my_input_file:\n",
    "        [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
    "    my_output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
